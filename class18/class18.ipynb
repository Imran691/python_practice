{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe\n",
    "* Add columns\n",
    "    * Add one column\n",
    "    * Add multiple columns\n",
    "* Delete column\n",
    "* Change data type of column\n",
    "* map()\n",
    "* apply()\n",
    "    * on one column\n",
    "    * on multiple columns\n",
    "\n",
    "To join data we use\n",
    "* conact()\n",
    "    * axis\n",
    "        * axis = 0 (top to bottom)\n",
    "        * axis = 1 (left to right)\n",
    "\n",
    "To describe Data Frame\n",
    "* df.info(): totoal index, columns names and data type, total filled cells\n",
    "* df.describe(): mean, std, min (statistical properties) | applies only to numerical columns\n",
    "\n",
    "To select a sample from a DataFrame\n",
    "* dataframe.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can install multiple packages separated by space in one command\n",
    "%pip install pandas pandera numpy nptyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "import numpy as np\n",
    "from nptyping import NDArray, Shape, Int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total: int = 10000\n",
    "\n",
    "# 80, 100 are boundaries of random integers to be genarated\n",
    "# 3rd argument (total) is the number of random integers to be generated (no of rows): size of the Series\n",
    "\n",
    "# for Data Frame we need to pass the 3rd argument that is the size, in the form of tuple.\n",
    "# First member of the tuple will be no of rows & second member will be no of columns\n",
    "# Now we need to provide to the Shape[] a second argument that is no. of columns\n",
    "\n",
    "s1 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(80, 100, (total, 5))\n",
    "ss1 : pd.DataFrame = pd.DataFrame(s1, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])  # over riding s1 and converting it into Series\n",
    "\n",
    "s2 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(80, 100, (total, 5))\n",
    "ss2 : pd.DataFrame = pd.DataFrame(s2, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s3 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(70, 79, (total, 5))\n",
    "ss3 : pd.DataFrame = pd.DataFrame(s3, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s4 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(60, 69, (total, 5))\n",
    "ss4 : pd.DataFrame = pd.DataFrame(s4, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s5 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(50, 59, (total, 5))\n",
    "ss5 : pd.DataFrame = pd.DataFrame(s5, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s6 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(40, 49, (total, 5))\n",
    "ss6 : pd.DataFrame = pd.DataFrame(s6, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s7 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(33, 39, (total, 5))\n",
    "ss7 : pd.DataFrame = pd.DataFrame(s7, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])\n",
    "\n",
    "s8 : NDArray[Shape[str(total) + \"5\"], Int64] = np.random.randint(0, 32, (total, 5))\n",
    "ss8 : pd.DataFrame = pd.DataFrame(s8, columns=[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat()\n",
    "* To combine multiple DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df : pd.DataFrame = pd.concat([ss1, ss2, ss3, ss4, ss5, ss6, ss7, ss8])\n",
    "\n",
    "display(df.info())\n",
    "display(\"===============================================================\")\n",
    "\n",
    "display(df.describe())\n",
    "display(\"================================================================\")\n",
    "\n",
    "display(df.head())  # displays top rows of Data Frame\n",
    "display(\"================================================================\")\n",
    "\n",
    "display(df.tail())  # displays bottom rows of Data Frame\n",
    "display(\"================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a file with the name student.csv in the same directory\n",
    "df.to_csv(\"student.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the student.csv file\n",
    "df1 : pd.DataFrame = pd.read_csv(\"./student.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply operations on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract one column from Data frame\n",
    "    * dataframe['column']\n",
    "        * we can add new column if extracted with this method\n",
    "        * can get column with space between columns text (if columns name has multiple words with space between them)\n",
    "        \n",
    "    * dataframe.\n",
    "        * we can not add new column if extracted with this method\n",
    "        * can not get column with space between columns text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s1']\n",
    "# can also be extracted if is name is df['s1 physics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract two or more columns from Data Frame\n",
    "    * dataframe[['column1', 'column2']] # by passing list of columns in any order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['s1', 's2', 's5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new column\n",
    "* dataframe['new column'] = value of new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total'] = 500   # adds new column with title = 'Total' & value = 500\n",
    "#df['Total'] = 300   # updates column value to 300\n",
    "\n",
    "#del df['Total']     # deletes the column\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding values of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s1'] + 20   # will add 20 to each value of s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['s1'] + df['s2'] + df['s3'] + df['s4'] + df['s5'] # will add the values of s1 +  and onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Obtained'] = df['s1'] + df['s2'] + df['s3'] + df['s4'] + df['s5']   # adds a column with obtained marks\n",
    "df['Percentage'] = df['Obtained'] / df['Total'] * 100                   # adds a column with percentage\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply custom functions on columns (SeriesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grade(per: str) -> str:\n",
    "    if per >= 80:\n",
    "        return \"A+\"\n",
    "    elif per >= 70:\n",
    "        return \"A\"\n",
    "    elif per >= 60:\n",
    "        return \"B\"\n",
    "    elif per >= 50:\n",
    "        return \"C\"\n",
    "    elif per >= 40:\n",
    "        return \"D\"\n",
    "    elif per >= 33:\n",
    "        return \"E\"\n",
    "    else:\n",
    "        return \"F\"\n",
    "    \n",
    "grade(79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply our custom function with apply() method\n",
    "# we pass our custom function as argument to apply() method\n",
    "df['Grade'] = df['Percentage'].apply(grade)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply custom functions on multiple columns & return one or more than one column\n",
    "* loc\n",
    "    * dataframe[rows, columns]\n",
    "        * exact label values\n",
    "* iloc\n",
    "    * dataframe[rows, columns]\n",
    "        * numerical indexing values\n",
    "* at\n",
    "    * cell value with exact label\n",
    "* iat\n",
    "    * cell value with numerical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 : pd.DataFrame = pd.DataFrame(ss1)  # create dataframe consisting of ss1 only\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[1 : 10]  # direct slicing applied on rows index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:11 , 1:3] # numpy slicing applied on rows [1 to 11] & columns [1 to 3] index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[1:10, \"s1\":\"s3\"]    # numpy slicing applied on rows [1 to 11] & columns [1 to 3] labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.at[4,\"s1\"]  # value of single cell with row & column label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iat[4, 0]   # value of single cell with row & column index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply custom funcstion on multiple clumns & return one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_obtained(s1: int, s2: int, s3:int, s4:int, s5:int) -> int:\n",
    "    return s1 + s2 + s3 + s4 + s5\n",
    "def fn_obtained(s1: int, s2: int, s3:int, s4:int, s5:int) -> int:\n",
    "    return s1 + s2 + s3 + s4 + s5\n",
    "def fn_obtained(s1: int, s2: int, s3:int, s4:int, s5:int) -> int:\n",
    "    return s1 + s2 + s3 + s4 + s5\n",
    "\n",
    "# df1[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].apply(fn_obtained) # custom function can not be applied directly\n",
    "# instead we will used lambda function\n",
    "\n",
    "# df1[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].apply(lambda x:fn_obtained(*x), axis=1)\n",
    "\n",
    "# we can add obtained marks column in dataframe as below\n",
    "# we applied our custom function on multiple columns and returned one column\n",
    "\n",
    "\n",
    "df1['Obtained'] = df1[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].apply(lambda x:fn_obtained(*x), axis=1)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply custom funcstion on multiple clumns & return multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_obtained(s1: int, s2: int, s3:int, s4:int, s5:int) -> tuple[int, int, float, str]:\n",
    "    total : int = 500\n",
    "    obtained : int = s1 + s2 + s3 + s4 + s5\n",
    "    per : float = obtained / total * 100\n",
    "    grade: str = \"\"\n",
    "\n",
    "    if per >= 80:\n",
    "        grade = \"A+\"\n",
    "    elif per >= 70:\n",
    "        grade = \"A\"\n",
    "    elif per >= 60:\n",
    "        grade = \"B\"\n",
    "    elif per >= 50:\n",
    "        grade = \"C\"\n",
    "    elif per >= 40:\n",
    "        grade = \"D\"\n",
    "    elif per >= 33:\n",
    "        grade = \"E\"\n",
    "    else:\n",
    "        grade = \"F\"\n",
    "    \n",
    "    return total, obtained, per, grade\n",
    "\n",
    "df1[['Total', 'Obtained', 'Percentage', 'Grade']] = df1[[\"s1\", \"s2\", \"s3\", \"s4\", \"s5\"]].apply(lambda x:fn_obtained(*x), \n",
    "                                                                                            axis=1, \n",
    "                                                                                            result_type='expand') # to add multiple columns\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map() function\n",
    "* we now will add remarkes column by map() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "remarks: Dict[str, str] = {\n",
    "    \"A+\" : \"Excellent\",\n",
    "    \"A\" : \"Very good\",\n",
    "    \"B\" : \"Good\",\n",
    "    \"C\" : \"Fair\",\n",
    "    \"D\" : \"Poor\",\n",
    "    \"E\" : \"Very poor\",\n",
    "    \"F\" : \"Fail,\"\n",
    "}\n",
    "\n",
    "df1['Remarks'] = df1.Grade.map(remarks)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type casting on column names\n",
    "* astype\n",
    "* apply\n",
    "    * datatype name(str, int, list)\n",
    "    * function name (cell_value) : transformation in function body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()  # to obtain data types, we see that the data type of \"s1\" is 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to change the data type of \"s1\" from int64 to int32\n",
    "# but this will cahnge tha data type, but not update the data type in df1\n",
    "df1['s1'].astype(np.int32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to update the data type in df1, we need to over ride 's1' \n",
    "\n",
    "df1['s1'] = df1['s1'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see that the data type of s1 has been updated to int32\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the data type of 's2' by apply() method\n",
    "df1['s2'] = df1['s2'].apply(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can see that the data type of s2 has been updated to int32\n",
    "df1.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
